{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce6deb5c-72f2-4660-a00f-aff2c3a9642c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/llaurabat/micromamba/envs/causal-flows/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import causal_nf.utils.wandb_local as wandb_local\n",
    "import causal_nf.config as causal_nf_config\n",
    "from causal_nf.config import cfg\n",
    "import causal_nf.utils.training as causal_nf_train\n",
    "import os\n",
    "import glob\n",
    "import argparse\n",
    "from yacs.config import CfgNode \n",
    "import torch\n",
    "import causal_nf.utils.io as causal_nf_io\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df864a36-1129-4049-9e50-58bfbee4638e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from causal_nf.preparators.scm.scm_preparator import SCMPreparator\n",
    "from causal_nf.config import cfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a956ffd-5e6d-44bd-89e7-2f2a7795b021",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_file = \"/Users/llaurabat/Dropbox/Oxford/deep_copula_frugal/causal-flows/output_FF/729d30ec516811efbcaaacde48001122/last.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ce410bc-b3cd-470b-8191-678d803c8d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "args_list = []\n",
    "args =  CfgNode({'config_file': 'output_FF/729d30ec516811efbcaaacde48001122/wandb_local/config_local.yaml', \n",
    "                 'config_default_file': 'output_FF/729d30ec516811efbcaaacde48001122/wandb_local/default_config.yaml', \n",
    "                 'project': None, 'wandb_mode': 'disabled', 'wandb_group': None, \n",
    "                 'load_model': 'output_FF/729d30ec516811efbcaaacde48001122', 'delete_ckpt': False})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "596e899b-7852-43c3-8d70-abe423fccf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# args_list, args = causal_nf_config.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "862f1d92-ab34-4b90-ab7a-d0ee61bd4bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = causal_nf_config.build_config(\n",
    "    config_file=args.config_file,\n",
    "    args_list=args_list,\n",
    "    config_default_file=args.config_default_file,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96ff3734-710b-410b-9987-b63319cd911c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CfgNode({'root': '../Data', 'name': 'simpson', 'sem_name': 'non-linear', 'splits': [0.8, 0.1, 0.1], 'k_fold': 1, 'shuffle_train': True, 'single_split': False, 'loss': 'default', 'scale': 'default', 'num_samples': 25000, 'base_version': 1, 'add_noise': False, 'type': 'torch', 'use_edge_attr': False})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f748560d-65c1-4942-923e-8544e84884ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "causal_nf_config.assert_cfg_and_config(cfg, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61ef2e8f-8dcf-4787-ae4f-b528abcafd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preparator = SCMPreparator.loader(cfg.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0125900-5e6c-4ec9-b7bb-ab346293db7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing data...\n",
      "\n",
      "Preparing data...\n",
      "\n",
      "Preparing data...\n"
     ]
    }
   ],
   "source": [
    "preparator.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b24d42d8-f39d-4421-bc40-56d9853b5c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAF(\n",
      "  (transforms): ModuleList(\n",
      "    (0): MaskedAutoregressiveTransform(\n",
      "      (base): MonotonicAffineTransform()\n",
      "      (order): [0, 1, 2, 3]\n",
      "      (hyper): MaskedMLP(\n",
      "        (0): MaskedLinear(in_features=4, out_features=32, bias=True)\n",
      "        (1): ELU(alpha=1.0)\n",
      "        (2): MaskedLinear(in_features=32, out_features=32, bias=True)\n",
      "        (3): ELU(alpha=1.0)\n",
      "        (4): MaskedLinear(in_features=32, out_features=32, bias=True)\n",
      "        (5): ELU(alpha=1.0)\n",
      "        (6): MaskedLinear(in_features=32, out_features=8, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (base): DiagNormal(loc: torch.Size([4]), scale: torch.Size([4]))\n",
      ")\n",
      "\u001b[94m[INFO] Loading <class 'causal_nf.models.causal_nf.CausalNFightning'> from /Users/llaurabat/Dropbox/Oxford/deep_copula_frugal/causal-flows/output_FF/729d30ec516811efbcaaacde48001122/last.ckpt\u001b[0m\n",
      "scaler_transform StandardTransform(shift=tensor([-7.1542e-04,  1.4097e+00, -1.0386e-01,  2.1808e+00]), scale=tensor([1.0097, 0.8172, 1.5350, 0.4413]))\n",
      "StandardScaler(\n",
      "\t\tmu_=tensor([[-7.1542e-04,  1.4097e+00, -1.0386e-01,  2.1808e+00]]), \n",
      "\t\tscale_=tensor([[1.0097, 0.8172, 1.5350, 0.4413]])\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT: insert ckpt file otherwise it loads anyway bt something wrong\n",
    "model_lightning = causal_nf_train.load_model(cfg=cfg, preparator=preparator, ckpt_file=ckpt_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f915d719-e1db-4682-b9b1-7c4d005d928e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(model.model.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65257009-bebd-4ca1-9b74-b8f0d511e615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CausalNormalizingFlow(\n",
       "  (flow): MAF(\n",
       "    (transforms): ModuleList(\n",
       "      (0): MaskedAutoregressiveTransform(\n",
       "        (base): MonotonicAffineTransform()\n",
       "        (order): [0, 1, 2, 3]\n",
       "        (hyper): MaskedMLP(\n",
       "          (0): MaskedLinear(in_features=4, out_features=32, bias=True)\n",
       "          (1): ELU(alpha=1.0)\n",
       "          (2): MaskedLinear(in_features=32, out_features=32, bias=True)\n",
       "          (3): ELU(alpha=1.0)\n",
       "          (4): MaskedLinear(in_features=32, out_features=32, bias=True)\n",
       "          (5): ELU(alpha=1.0)\n",
       "          (6): MaskedLinear(in_features=32, out_features=8, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (base): DiagNormal(loc: torch.Size([4]), scale: torch.Size([4]))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model_lightning.model\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "150edbd7-811d-46c8-8de9-02646141746b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m[INFO] [0] num_batchees: 5\u001b[0m\n",
      "\u001b[94m[INFO] [1] num_batchees: 1\u001b[0m\n",
      "\u001b[94m[INFO] [2] num_batchees: 1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "loaders = preparator.get_dataloaders(\n",
    "    batch_size=cfg.train.batch_size, num_workers=cfg.train.num_workers\n",
    ")\n",
    "\n",
    "for i, loader in enumerate(loaders):\n",
    "    causal_nf_io.print_info(f\"[{i}] num_batchees: {len(loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae3374a-410a-457f-9548-402a3f69e97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(loaders[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3641337-67c1-4bfa-892b-efab3943db18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict from model class\n",
    "# torch.random.manual_seed(8)\n",
    "# loss_dict = model_lightning.predict(\n",
    "#     batch=next(iter(loaders[2])),\n",
    "#     observational=False,\n",
    "#     intervene=False,\n",
    "#     counterfactual=False,\n",
    "#     ate=True,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49834a4b-ee10-4563-8a72-a9fcbccdd21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual implementation of my_predict\n",
    "\n",
    "# output = {}\n",
    "# x = batch[0] # is this u or x? I hope x\n",
    "# n = x.shape[0]\n",
    "# with torch.enable_grad():\n",
    "#     output[\"log_prob_true\"] = preparator.log_prob(x)\n",
    "\n",
    "# log_prob = model.log_prob(x, scaler=preparator.scaler_transform)\n",
    "# output[\"loss\"] = -log_prob\n",
    "# output[\"log_prob\"] = log_prob\n",
    "# intervention_list = preparator.get_ate_list()\n",
    "\n",
    "# for int_dict in intervention_list:\n",
    "#     name = int_dict[\"name\"]\n",
    "#     a = int_dict[\"a\"]#1.\n",
    "#     b = int_dict[\"b\"]#0.\n",
    "#     index = int_dict[\"index\"]\n",
    "    \n",
    "#     ate = model_lightning.model.compute_ate(\n",
    "#         index,\n",
    "#         a=a,\n",
    "#         b=b,\n",
    "#         num_samples=10000,\n",
    "#         scaler=preparator.scaler_transform,\n",
    "#     )\n",
    "\n",
    "#     print(ate_true)\n",
    "\n",
    "#     ate_true = preparator.compute_ate(\n",
    "#         index, a=a, b=b, num_samples=10000\n",
    "#     )\n",
    "\n",
    "#     diff_ate = ate_true - ate\n",
    "\n",
    "#     rmse = torch.sqrt((diff_ate**2).sum())\n",
    "#     output[f\"rmse_ate_x{index + 1}={name}\"] = rmse\n",
    "# output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e569b90b-b571-4b0f-b4de-c947162cf395",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_predict(\n",
    "        self,\n",
    "        batch,\n",
    "        observational=False,\n",
    "        intervene=False,\n",
    "        counterfactual=False,\n",
    "        ate=False,\n",
    "        intervention_list=None,\n",
    "    ):\n",
    "        output = {}\n",
    "        x = batch[0].to(self.device)\n",
    "        n = x.shape[0]\n",
    "        with torch.enable_grad():\n",
    "            output[\"log_prob_true\"] = self.preparator.log_prob(x)\n",
    "\n",
    "        tic = time.time()\n",
    "        log_prob = self.model.log_prob(x, scaler=self.preparator.scaler_transform)\n",
    "        output[\"time_log_prob\"] = self.compute_time(tic, n)\n",
    "        output[\"loss\"] = -log_prob\n",
    "        output[\"log_prob\"] = log_prob\n",
    "\n",
    "        if observational:\n",
    "            tic = time.time()\n",
    "            obs_dict = self.model.sample((n,))\n",
    "            output[\"time_sample_obs\"] = self.compute_time(tic, n)\n",
    "            x_obs_norm = obs_dict[\"x_obs\"]\n",
    "            x_obs = self.input_scaler.inverse_transform(x_obs_norm, inplace=False)\n",
    "            if self.plot:\n",
    "                output[\"x\"] = self.preparator.post_process(x)\n",
    "            if self.plot:\n",
    "                output[\"x_obs\"] = self.preparator.post_process(x_obs)\n",
    "            mmd_value = maximum_mean_discrepancy(x, x_obs, sigma=None)\n",
    "            output[f\"mmd_obs\"] = mmd_value\n",
    "            with torch.enable_grad():\n",
    "                log_p_with_x_sample = self.preparator.log_prob(x_obs)\n",
    "                log_p_with_x = self.preparator.log_prob(x)\n",
    "            output[\"log_prob_p\"] = log_p_with_x_sample\n",
    "            log_q_with_x_sample = self.model.log_prob(\n",
    "                x_obs, scaler=self.preparator.scaler_transform\n",
    "            )\n",
    "\n",
    "            kl_distance = (\n",
    "                log_p_with_x + log_q_with_x_sample - log_p_with_x_sample - log_prob\n",
    "            )\n",
    "            output[\"kl_distance\"] = kl_distance\n",
    "\n",
    "        if intervene:\n",
    "            if intervention_list is None:\n",
    "                intervention_list = self.preparator.get_intervention_list()\n",
    "            delta_times = []\n",
    "            for int_dict in intervention_list:\n",
    "                name = int_dict[\"name\"]\n",
    "                value = int_dict[\"value\"]\n",
    "                index = int_dict[\"index\"]\n",
    "                tic = time.time()\n",
    "                x_int = self.model.intervene(\n",
    "                    index=index,\n",
    "                    value=value,\n",
    "                    shape=(n,),\n",
    "                    scaler=self.preparator.scaler_transform,\n",
    "                )\n",
    "                delta_times.append(self.compute_time(tic, n))\n",
    "\n",
    "\n",
    "                if self.plot:\n",
    "                    output[f\"x_int_{index + 1}={name}\"] = self.preparator.post_process(\n",
    "                        x_int\n",
    "                    )\n",
    "\n",
    "                x_int_true = self.preparator.intervene(\n",
    "                    index=index, value=value, shape=(n,)\n",
    "                )\n",
    "                if self.plot:\n",
    "                    output[\n",
    "                        f\"x_int_{index + 1}={name}_true\"\n",
    "                    ] = self.preparator.post_process(x_int_true)\n",
    "\n",
    "                mmd_value = maximum_mean_discrepancy(x_int, x_int_true, sigma=None)\n",
    "                output[f\"mmd_int_x{index + 1}={name}\"] = mmd_value\n",
    "\n",
    "            delta_time = torch.stack(delta_times).mean()\n",
    "            output[\"time_intervene\"] = delta_time\n",
    "        if counterfactual:\n",
    "            if intervention_list is None:\n",
    "                intervention_list = self.preparator.get_intervention_list()\n",
    "            delta_times = []\n",
    "            for int_dict in intervention_list:\n",
    "                name = int_dict[\"name\"]\n",
    "                value = int_dict[\"value\"]\n",
    "                index = int_dict[\"index\"]\n",
    "                tic = time.time()\n",
    "                x_cf = self.model.compute_counterfactual(\n",
    "                    x_factual=x,\n",
    "                    index=index,\n",
    "                    value=value,\n",
    "                    scaler=self.preparator.scaler_transform,\n",
    "                )\n",
    "                delta_times.append(self.compute_time(tic, n))\n",
    "\n",
    "                x_cf_true = self.preparator.compute_counterfactual(x, index, value)\n",
    "\n",
    "                diff_cf = x_cf_true - x_cf\n",
    "\n",
    "                rmse = torch.sqrt((diff_cf**2).sum(1))\n",
    "                output[f\"rmse_cf_x{index + 1}={name}\"] = rmse\n",
    "                mae = diff_cf.abs().sum(1)\n",
    "                output[f\"mse_cf_x{index + 1}={name}\"] = mae\n",
    "\n",
    "            delta_time = torch.stack(delta_times).mean()\n",
    "            output[\"time_cf\"] = delta_time\n",
    "\n",
    "        if ate:\n",
    "            if intervention_list is None:\n",
    "                intervention_list = self.preparator.get_ate_list()\n",
    "            delta_times = []\n",
    "            for int_dict in intervention_list:\n",
    "                name = int_dict[\"name\"]\n",
    "                a = int_dict[\"a\"]\n",
    "                b = int_dict[\"b\"]\n",
    "                index = int_dict[\"index\"]\n",
    "                tic = time.time()\n",
    "                ate = self.model.compute_ate(\n",
    "                    index,\n",
    "                    a=a,\n",
    "                    b=b,\n",
    "                    num_samples=10000,\n",
    "                    scaler=self.preparator.scaler_transform,\n",
    "                )\n",
    "                delta_times.append(self.compute_time(tic, 10000))\n",
    "\n",
    "                ate_true = self.preparator.compute_ate(\n",
    "                    index, a=a, b=b, num_samples=10000\n",
    "                )\n",
    "\n",
    "                diff_ate = ate_true - ate\n",
    "\n",
    "                rmse = torch.sqrt((diff_ate**2).sum())\n",
    "                output[f\"rmse_ate_x{index + 1}={name}\"] = rmse\n",
    "\n",
    "            delta_time = torch.stack(delta_times).mean()\n",
    "            output[\"time_ate\"] = delta_time\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6644606e-ecea-4ff4-9ae1-df35deb1e043",
   "metadata": {},
   "outputs": [],
   "source": [
    "intervention_list = [{'name': '1_0', 'a': 1., 'b': 0., 'index': 0},]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2a6d5998-d638-4e59-a81d-c37babf7478d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'log_prob_true': tensor([-2.8672, -2.4891, -6.4312,  ..., -4.2171, -2.1910, -1.8383]),\n",
       " 'time_log_prob': tensor(0.9432),\n",
       " 'loss': tensor([2.5407, 2.3248, 7.3806,  ..., 4.2023, 2.1255, 2.3977],\n",
       "        grad_fn=<NegBackward0>),\n",
       " 'log_prob': tensor([-2.5407, -2.3248, -7.3806,  ..., -4.2023, -2.1255, -2.3977],\n",
       "        grad_fn=<AddBackward0>),\n",
       " 'rmse_ate_x1=1_0': tensor(0.0135),\n",
       " 'time_ate': tensor(4.4213)}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bri = my_predict(\n",
    "        self=model_lightning,\n",
    "        batch=batch,\n",
    "        observational=False,\n",
    "        intervene=False,\n",
    "        counterfactual=False,\n",
    "        ate=True,\n",
    "        intervention_list=intervention_list,\n",
    "    )\n",
    "bri"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
