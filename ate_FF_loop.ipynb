{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce6deb5c-72f2-4660-a00f-aff2c3a9642c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/llaurabat/micromamba/envs/causal-flows/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import causal_nf.utils.wandb_local as wandb_local\n",
    "import causal_nf.config as causal_nf_config\n",
    "from causal_nf.config import cfg\n",
    "import causal_nf.utils.training as causal_nf_train\n",
    "import os\n",
    "import glob\n",
    "import argparse\n",
    "from yacs.config import CfgNode \n",
    "import torch\n",
    "import causal_nf.utils.io as causal_nf_io\n",
    "import time\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df864a36-1129-4049-9e50-58bfbee4638e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from causal_nf.preparators.FF_preparator import FFPreparator\n",
    "from causal_nf.config import cfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41c2fe47-3983-43d5-a73e-cf41da72bebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_dict = {'M1_ckpt_files':[\"/Users/llaurabat/Dropbox/Oxford/deep_copula_frugal/causal-flows/output_FF_final_ate1_M1_1/a6cbbd08526111efa71facde48001122/last.ckpt\",\n",
    "                             \"/Users/llaurabat/Dropbox/Oxford/deep_copula_frugal/causal-flows/output_FF_final_ate1_M1_2/a6cbbd08526111efa71facde48001122/last.ckpt\",\n",
    "                             \"/Users/llaurabat/Dropbox/Oxford/deep_copula_frugal/causal-flows/output_FF_final_ate1_M1_3/a6cbbd08526111efa71facde48001122/last.ckpt\",\n",
    "                             \"/Users/llaurabat/Dropbox/Oxford/deep_copula_frugal/causal-flows/output_FF_final_ate1_M1_4/a6cbbd08526111efa71facde48001122/last.ckpt\",\n",
    "                             \"/Users/llaurabat/Dropbox/Oxford/deep_copula_frugal/causal-flows/output_FF_final_ate1_M1_5/a6cbbd08526111efa71facde48001122/last.ckpt\"],\n",
    "            'M2_ckpt_files':[\"/Users/llaurabat/Dropbox/Oxford/deep_copula_frugal/causal-flows/output_FF_final_ate1_M2_1/a6cbbd08526111efa71facde48001122/last.ckpt\",\n",
    "                            \"/Users/llaurabat/Dropbox/Oxford/deep_copula_frugal/causal-flows/output_FF_final_ate1_M2_2/a6cbbd08526111efa71facde48001122/last.ckpt\",\n",
    "                            \"/Users/llaurabat/Dropbox/Oxford/deep_copula_frugal/causal-flows/output_FF_final_ate1_M2_3/a6cbbd08526111efa71facde48001122/last.ckpt\",\n",
    "                            \"/Users/llaurabat/Dropbox/Oxford/deep_copula_frugal/causal-flows/output_FF_final_ate1_M2_4/a6cbbd08526111efa71facde48001122/last.ckpt\",\n",
    "                            \"/Users/llaurabat/Dropbox/Oxford/deep_copula_frugal/causal-flows/output_FF_final_ate1_M2_5/a6cbbd08526111efa71facde48001122/last.ckpt\"],}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e4b60f-1047-4b14-9070-e90a89c5597b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01fa8da7-7b3a-4a40-bd9a-d15ff5a62d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing data...\n",
      "\n",
      "Preparing data...\n",
      "\n",
      "Preparing data...\n",
      "NSF(\n",
      "  (transforms): ModuleList(\n",
      "    (0): MaskedAutoregressiveTransform(\n",
      "      (base): MonotonicRQSTransform(bins=8)\n",
      "      (order): [0, 1, 2, 3, 4, 5]\n",
      "      (hyper): MaskedMLP(\n",
      "        (0): MaskedLinear(in_features=6, out_features=32, bias=True)\n",
      "        (1): ELU(alpha=1.0)\n",
      "        (2): MaskedLinear(in_features=32, out_features=32, bias=True)\n",
      "        (3): ELU(alpha=1.0)\n",
      "        (4): MaskedLinear(in_features=32, out_features=32, bias=True)\n",
      "        (5): ELU(alpha=1.0)\n",
      "        (6): MaskedLinear(in_features=32, out_features=138, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (base): DiagNormal(loc: torch.Size([6]), scale: torch.Size([6]))\n",
      ")\n",
      "\u001b[94m[INFO] Loading <class 'causal_nf.models.causal_nf.CausalNFightning'> from /Users/llaurabat/Dropbox/Oxford/deep_copula_frugal/causal-flows/output_FF_final_ate1/a6cbbd08526111efa71facde48001122/last.ckpt\u001b[0m\n",
      "scaler_transform StandardTransform(shift=tensor([2.7234, 2.7408, 2.7082, 2.6903, 0.9523, 1.9587]), scale=tensor([2.7295, 2.6963, 2.7701, 2.7185, 0.2133, 1.0559]))\n",
      "StandardScaler(\n",
      "\t\tmu_=tensor([[2.7234, 2.7408, 2.7082, 2.6903, 0.9523, 1.9587]]), \n",
      "\t\tscale_=tensor([[2.7295, 2.6963, 2.7701, 2.7185, 0.2133, 1.0559]])\n",
      ")\n",
      "Model M1_ckpt_files dataset 0 mean: 0.7486189\n",
      "Model M1_ckpt_files dataset 0 std: 0.012919243\n",
      "\n",
      "Preparing data...\n",
      "\n",
      "Preparing data...\n",
      "\n",
      "Preparing data...\n",
      "NSF(\n",
      "  (transforms): ModuleList(\n",
      "    (0): MaskedAutoregressiveTransform(\n",
      "      (base): MonotonicRQSTransform(bins=8)\n",
      "      (order): [0, 1, 2, 3, 4, 5]\n",
      "      (hyper): MaskedMLP(\n",
      "        (0): MaskedLinear(in_features=6, out_features=32, bias=True)\n",
      "        (1): ELU(alpha=1.0)\n",
      "        (2): MaskedLinear(in_features=32, out_features=32, bias=True)\n",
      "        (3): ELU(alpha=1.0)\n",
      "        (4): MaskedLinear(in_features=32, out_features=32, bias=True)\n",
      "        (5): ELU(alpha=1.0)\n",
      "        (6): MaskedLinear(in_features=32, out_features=138, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (base): DiagNormal(loc: torch.Size([6]), scale: torch.Size([6]))\n",
      ")\n",
      "\u001b[94m[INFO] Loading <class 'causal_nf.models.causal_nf.CausalNFightning'> from /Users/llaurabat/Dropbox/Oxford/deep_copula_frugal/causal-flows/output_FF_final_ate1/a6cbbd08526111efa71facde48001122/last.ckpt\u001b[0m\n",
      "scaler_transform StandardTransform(shift=tensor([2.7234, 2.7408, 2.7082, 2.6903, 0.9523, 1.9587]), scale=tensor([2.7295, 2.6963, 2.7701, 2.7185, 0.2133, 1.0559]))\n",
      "StandardScaler(\n",
      "\t\tmu_=tensor([[2.7234, 2.7408, 2.7082, 2.6903, 0.9523, 1.9587]]), \n",
      "\t\tscale_=tensor([[2.7295, 2.6963, 2.7701, 2.7185, 0.2133, 1.0559]])\n",
      ")\n",
      "Model M2_ckpt_files dataset 0 mean: 0.7486189\n",
      "Model M2_ckpt_files dataset 0 std: 0.012919243\n"
     ]
    }
   ],
   "source": [
    "for mod_ix, (mod, check_files) in enumerate(info_dict.items()):\n",
    "    results[f'M{mod_ix+1}'] = []\n",
    "    for c_ix, check_file in enumerate(check_files):\n",
    "        components = os.path.normpath(check_file).split(os.sep)\n",
    "        folder = components[-3]\n",
    "        check_code = components[-2]\n",
    "\n",
    "        args_list = []\n",
    "        args =  CfgNode({'config_file': f'{folder}/{check_code}/wandb_local/config_local.yaml', \n",
    "                         'config_default_file': f'{folder}/{check_code}/wandb_local/default_config.yaml', \n",
    "                         'project': None, 'wandb_mode': 'disabled', 'wandb_group': None, \n",
    "                         'load_model': f'{folder}/{check_code}', 'delete_ckpt': False})\n",
    "        config = causal_nf_config.build_config(\n",
    "        config_file=args.config_file,\n",
    "            args_list=args_list,\n",
    "            config_default_file=args.config_default_file,\n",
    "        )\n",
    "        causal_nf_config.assert_cfg_and_config(cfg, config)\n",
    "        preparator = FFPreparator.loader(cfg.dataset)\n",
    "        preparator.prepare_data()\n",
    "        model_lightning = causal_nf_train.load_model(cfg=cfg, preparator=preparator, ckpt_file=check_file)\n",
    "        model = model_lightning.model\n",
    "        model.eval()\n",
    "        loaders = preparator.get_dataloaders(\n",
    "            batch_size=cfg.train.batch_size, num_workers=cfg.train.num_workers\n",
    "        )\n",
    "        \n",
    "        # for i, loader in enumerate(loaders):\n",
    "        #     causal_nf_io.print_info(f\"[{i}] num_batchees: {len(loader)}\")\n",
    "\n",
    "        # manual implementation of my_predict\n",
    "        n_rounds = 5\n",
    "        ates = []\n",
    "        seeds = np.arange(n_rounds)\n",
    "        batch = next(iter(loaders[-1]))\n",
    "        for i, seed in enumerate(seeds):\n",
    "            output = {}\n",
    "            x = batch[0] # is this u or x? I hope x\n",
    "            n = x.shape[0]\n",
    "            with torch.enable_grad():\n",
    "                output[\"log_prob_true\"] = preparator.log_prob(x)\n",
    "            \n",
    "            log_prob = model.log_prob(x, scaler=preparator.scaler_transform)\n",
    "            output[\"loss\"] = -log_prob\n",
    "            output[\"log_prob\"] = log_prob\n",
    "            # intervention_list = preparator.get_ate_list()\n",
    "            \n",
    "            int_dict = {'name': '1_0', 'a': 1., 'b': 0., 'index': 4}\n",
    "            \n",
    "        \n",
    "            name = int_dict[\"name\"]\n",
    "            a = int_dict[\"a\"]#1.\n",
    "            b = int_dict[\"b\"]#0.\n",
    "            index = int_dict[\"index\"]\n",
    "        \n",
    "            torch.random.manual_seed(seed) \n",
    "            ate = model_lightning.model.compute_ate(\n",
    "                index,\n",
    "                a=a,\n",
    "                b=b,\n",
    "                num_samples=10000,\n",
    "                scaler=preparator.scaler_transform,\n",
    "            )\n",
    "            \n",
    "            ates.append(ate.detach().numpy())\n",
    "        \n",
    "        ates = np.array(ates)\n",
    "        ates_y = ates[:,-1]\n",
    "        mean = ates_y.mean()\n",
    "        std =  ates_y.std()\n",
    "        print(f'Model {mod_ix+1} dataset {c_ix+1} mean:', mean)\n",
    "        print(f'Model {mod_ix+1} dataset {c_ix+1} std:', std)\n",
    "        results[f'M{mod_ix+1}'].append(ates_y)\n",
    "        \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a956ffd-5e6d-44bd-89e7-2f2a7795b021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ckpt_file = \"/Users/llaurabat/Dropbox/Oxford/deep_copula_frugal/causal-flows/output_FF_final/edf3624c525411ef8eecacde48001122/last.ckpt\"\n",
    "# ckpt_file = \"/Users/llaurabat/Dropbox/Oxford/deep_copula_frugal/causal-flows/output_FF_final_adj_ON/1f995ea8525c11efbcefacde48001122/last.ckpt\"\n",
    "ckpt_file = \"/Users/llaurabat/Dropbox/Oxford/deep_copula_frugal/causal-flows/output_FF_final_ate1/a6cbbd08526111efa71facde48001122/last.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ce410bc-b3cd-470b-8191-678d803c8d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "args_list = []\n",
    "args =  CfgNode({'config_file': 'output_FF_final_ate1/a6cbbd08526111efa71facde48001122/wandb_local/config_local.yaml', \n",
    "                 'config_default_file': 'output_FF_final_ate1/a6cbbd08526111efa71facde48001122/wandb_local/default_config.yaml', \n",
    "                 'project': None, 'wandb_mode': 'disabled', 'wandb_group': None, \n",
    "                 'load_model': 'output_FF_final_ate1/a6cbbd08526111efa71facde48001122', 'delete_ckpt': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "596e899b-7852-43c3-8d70-abe423fccf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# args_list, args = causal_nf_config.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "862f1d92-ab34-4b90-ab7a-d0ee61bd4bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = causal_nf_config.build_config(\n",
    "    config_file=args.config_file,\n",
    "    args_list=args_list,\n",
    "    config_default_file=args.config_default_file,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "96ff3734-710b-410b-9987-b63319cd911c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CfgNode({'root': '../Data', 'name': 'FF_data', 'sem_name': 'dummy', 'splits': [0.8, 0.1, 0.1], 'k_fold': 1, 'shuffle_train': True, 'single_split': False, 'loss': 'default', 'scale': 'default', 'num_samples': 1000, 'base_version': 1, 'add_noise': False, 'type': 'torch', 'use_edge_attr': False})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f748560d-65c1-4942-923e-8544e84884ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "causal_nf_config.assert_cfg_and_config(cfg, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "61ef2e8f-8dcf-4787-ae4f-b528abcafd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preparator = FFPreparator.loader(cfg.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f0125900-5e6c-4ec9-b7bb-ab346293db7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing data...\n",
      "\n",
      "Preparing data...\n",
      "\n",
      "Preparing data...\n"
     ]
    }
   ],
   "source": [
    "preparator.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b24d42d8-f39d-4421-bc40-56d9853b5c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NSF(\n",
      "  (transforms): ModuleList(\n",
      "    (0): MaskedAutoregressiveTransform(\n",
      "      (base): MonotonicRQSTransform(bins=8)\n",
      "      (order): [0, 1, 2, 3, 4, 5]\n",
      "      (hyper): MaskedMLP(\n",
      "        (0): MaskedLinear(in_features=6, out_features=32, bias=True)\n",
      "        (1): ELU(alpha=1.0)\n",
      "        (2): MaskedLinear(in_features=32, out_features=32, bias=True)\n",
      "        (3): ELU(alpha=1.0)\n",
      "        (4): MaskedLinear(in_features=32, out_features=32, bias=True)\n",
      "        (5): ELU(alpha=1.0)\n",
      "        (6): MaskedLinear(in_features=32, out_features=138, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (base): DiagNormal(loc: torch.Size([6]), scale: torch.Size([6]))\n",
      ")\n",
      "\u001b[94m[INFO] Loading <class 'causal_nf.models.causal_nf.CausalNFightning'> from /Users/llaurabat/Dropbox/Oxford/deep_copula_frugal/causal-flows/output_FF_final_ate1/a6cbbd08526111efa71facde48001122/last.ckpt\u001b[0m\n",
      "scaler_transform StandardTransform(shift=tensor([2.7234, 2.7408, 2.7082, 2.6903, 0.9523, 1.9587]), scale=tensor([2.7295, 2.6963, 2.7701, 2.7185, 0.2133, 1.0559]))\n",
      "StandardScaler(\n",
      "\t\tmu_=tensor([[2.7234, 2.7408, 2.7082, 2.6903, 0.9523, 1.9587]]), \n",
      "\t\tscale_=tensor([[2.7295, 2.6963, 2.7701, 2.7185, 0.2133, 1.0559]])\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT: insert ckpt file otherwise it loads anyway bt something wrong\n",
    "model_lightning = causal_nf_train.load_model(cfg=cfg, preparator=preparator, ckpt_file=ckpt_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f915d719-e1db-4682-b9b1-7c4d005d928e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(model.model.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "65257009-bebd-4ca1-9b74-b8f0d511e615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CausalNormalizingFlow(\n",
       "  (flow): NSF(\n",
       "    (transforms): ModuleList(\n",
       "      (0): MaskedAutoregressiveTransform(\n",
       "        (base): MonotonicRQSTransform(bins=8)\n",
       "        (order): [0, 1, 2, 3, 4, 5]\n",
       "        (hyper): MaskedMLP(\n",
       "          (0): MaskedLinear(in_features=6, out_features=32, bias=True)\n",
       "          (1): ELU(alpha=1.0)\n",
       "          (2): MaskedLinear(in_features=32, out_features=32, bias=True)\n",
       "          (3): ELU(alpha=1.0)\n",
       "          (4): MaskedLinear(in_features=32, out_features=32, bias=True)\n",
       "          (5): ELU(alpha=1.0)\n",
       "          (6): MaskedLinear(in_features=32, out_features=138, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (base): DiagNormal(loc: torch.Size([6]), scale: torch.Size([6]))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model_lightning.model\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "150edbd7-811d-46c8-8de9-02646141746b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m[INFO] [0] num_batchees: 1\u001b[0m\n",
      "\u001b[94m[INFO] [1] num_batchees: 1\u001b[0m\n",
      "\u001b[94m[INFO] [2] num_batchees: 1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "loaders = preparator.get_dataloaders(\n",
    "    batch_size=cfg.train.batch_size, num_workers=cfg.train.num_workers\n",
    ")\n",
    "\n",
    "for i, loader in enumerate(loaders):\n",
    "    causal_nf_io.print_info(f\"[{i}] num_batchees: {len(loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cae3374a-410a-457f-9548-402a3f69e97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(loaders[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0ab90de4-7b57-4923-8ca9-473dba85e5c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 6])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d3641337-67c1-4bfa-892b-efab3943db18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict from model class\n",
    "# torch.random.manual_seed(8)\n",
    "# loss_dict = model_lightning.predict(\n",
    "#     batch=next(iter(loaders[2])),\n",
    "#     observational=False,\n",
    "#     intervene=False,\n",
    "#     counterfactual=False,\n",
    "#     ate=True,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "872e5308-46b7-41c9-8961-26ae0ab1a733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.7469618\n",
      "std: 0.013235588\n"
     ]
    }
   ],
   "source": [
    "# manual implementation of my_predict\n",
    "n_rounds = 25\n",
    "ates = []\n",
    "seeds = np.arange(n_rounds)\n",
    "for i, seed in enumerate(seeds):\n",
    "    output = {}\n",
    "    x = batch[0] # is this u or x? I hope x\n",
    "    n = x.shape[0]\n",
    "    with torch.enable_grad():\n",
    "        output[\"log_prob_true\"] = preparator.log_prob(x)\n",
    "    \n",
    "    log_prob = model.log_prob(x, scaler=preparator.scaler_transform)\n",
    "    output[\"loss\"] = -log_prob\n",
    "    output[\"log_prob\"] = log_prob\n",
    "    # intervention_list = preparator.get_ate_list()\n",
    "    \n",
    "    int_dict = {'name': '1_0', 'a': 1., 'b': 0., 'index': 4}\n",
    "    \n",
    "\n",
    "    name = int_dict[\"name\"]\n",
    "    a = int_dict[\"a\"]#1.\n",
    "    b = int_dict[\"b\"]#0.\n",
    "    index = int_dict[\"index\"]\n",
    "\n",
    "    torch.random.manual_seed(seed) \n",
    "    ate = model_lightning.model.compute_ate(\n",
    "        index,\n",
    "        a=a,\n",
    "        b=b,\n",
    "        num_samples=10000,\n",
    "        scaler=preparator.scaler_transform,\n",
    "    )\n",
    "    \n",
    "    ates.append(ate.detach().numpy())\n",
    "\n",
    "ates = np.array(ates)\n",
    "ates_y = ates[:,-1]\n",
    "mean = ates_y.mean()\n",
    "std =  ates_y.std()\n",
    "print('mean:', mean)\n",
    "print('std:', std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e569b90b-b571-4b0f-b4de-c947162cf395",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_predict(\n",
    "        self,\n",
    "        batch,\n",
    "        observational=False,\n",
    "        intervene=False,\n",
    "        counterfactual=False,\n",
    "        ate=False,\n",
    "        intervention_list=None,\n",
    "    ):\n",
    "        output = {}\n",
    "        x = batch[0].to(self.device)\n",
    "        n = x.shape[0]\n",
    "        with torch.enable_grad():\n",
    "            output[\"log_prob_true\"] = self.preparator.log_prob(x)\n",
    "\n",
    "        tic = time.time()\n",
    "        log_prob = self.model.log_prob(x, scaler=self.preparator.scaler_transform)\n",
    "        output[\"time_log_prob\"] = self.compute_time(tic, n)\n",
    "        output[\"loss\"] = -log_prob\n",
    "        output[\"log_prob\"] = log_prob\n",
    "\n",
    "        if ate:\n",
    "            if intervention_list is None:\n",
    "                intervention_list = self.preparator.get_ate_list()\n",
    "            delta_times = []\n",
    "            for int_dict in intervention_list:\n",
    "                name = int_dict[\"name\"]\n",
    "                a = int_dict[\"a\"]\n",
    "                b = int_dict[\"b\"]\n",
    "                index = int_dict[\"index\"]\n",
    "                tic = time.time()\n",
    "                ate = self.model.compute_ate(\n",
    "                    index,\n",
    "                    a=a,\n",
    "                    b=b,\n",
    "                    num_samples=10000,\n",
    "                    scaler=self.preparator.scaler_transform,\n",
    "                )\n",
    "                delta_times.append(self.compute_time(tic, 10000))\n",
    "\n",
    "                ate_true = self.preparator.compute_ate(\n",
    "                    index, a=a, b=b, num_samples=10000\n",
    "                )\n",
    "\n",
    "                diff_ate = ate_true - ate\n",
    "\n",
    "                rmse = torch.sqrt((diff_ate**2).sum())\n",
    "                output[f\"rmse_ate_x{index + 1}={name}\"] = rmse\n",
    "\n",
    "            delta_time = torch.stack(delta_times).mean()\n",
    "            output[\"time_ate\"] = delta_time\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6644606e-ecea-4ff4-9ae1-df35deb1e043",
   "metadata": {},
   "outputs": [],
   "source": [
    "intervention_list = [{'name': '1_0', 'a': 1., 'b': 0., 'index': 0},]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2a6d5998-d638-4e59-a81d-c37babf7478d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'log_prob_true': tensor([-2.8672, -2.4891, -6.4312,  ..., -4.2171, -2.1910, -1.8383]),\n",
       " 'time_log_prob': tensor(0.9432),\n",
       " 'loss': tensor([2.5407, 2.3248, 7.3806,  ..., 4.2023, 2.1255, 2.3977],\n",
       "        grad_fn=<NegBackward0>),\n",
       " 'log_prob': tensor([-2.5407, -2.3248, -7.3806,  ..., -4.2023, -2.1255, -2.3977],\n",
       "        grad_fn=<AddBackward0>),\n",
       " 'rmse_ate_x1=1_0': tensor(0.0135),\n",
       " 'time_ate': tensor(4.4213)}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bri = my_predict(\n",
    "        self=model_lightning,\n",
    "        batch=batch,\n",
    "        observational=False,\n",
    "        intervene=False,\n",
    "        counterfactual=False,\n",
    "        ate=True,\n",
    "        intervention_list=intervention_list,\n",
    "    )\n",
    "bri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f492db-bf45-4618-b3bb-e51094068498",
   "metadata": {},
   "outputs": [],
   "source": [
    "python main.py --config_file causal_nf/configs/FF_configs.yaml --wandb_mode disabled --project FF_data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
